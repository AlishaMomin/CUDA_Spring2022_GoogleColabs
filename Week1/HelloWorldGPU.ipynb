{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HelloWorldGPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZUKWKjP49D7VhQqYcw83F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmmovania/CUDA_Spring2022_GoogleColabs/blob/main/Week1/HelloWorldGPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBUHmmqQHOS-",
        "outputId": "9759bacb-3e23-429c-e99c-a6f4a97d83b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local\n",
            "  File: cuda -> /usr/local/cuda-10.1\n",
            "  Size: 20        \tBlocks: 0          IO Block: 4096   symbolic link\n",
            "Device: 24h/36d\tInode: 98          Links: 1\n",
            "Access: (0777/lrwxrwxrwx)  Uid: (    0/    root)   Gid: (    0/    root)\n",
            "Access: 2022-01-10 04:21:00.329678835 +0000\n",
            "Modify: 2022-01-10 04:21:00.221679107 +0000\n",
            "Change: 2022-01-10 04:21:00.221679107 +0000\n",
            " Birth: -\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-aq9r9gvk\n",
            "  Running command git clone -q https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-aq9r9gvk\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4305 sha256=00a2abfd1980521c429e04cca023ac06873522f82e4432d5ede00b9183e01cd1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3b9hj7ve/wheels/c5/2b/c0/87008e795a14bbcdfc7c846a00d06981916331eb980b6c8bdf\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "directory /usr/local/src already exists\n",
            "Out bin /usr/local/result.out\n"
          ]
        }
      ],
      "source": [
        "%cd /usr/local/\n",
        "!rm -rf cuda\n",
        "!ln -s /usr/local/cuda-10.1 /usr/local/cuda\n",
        "!stat cuda\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aikKbs6TMEp6",
        "outputId": "f917ef87-837d-42eb-e22d-ec5371bd9bc1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 10 04:21:06 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void HelloKernel() {\n",
        "    printf(\"\\tHello from GPU (device)\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  printf(\"Hello from CPU (host) before kernel execution\\n\");\n",
        "  HelloKernel<<<1,32>>>();\n",
        "  cudaDeviceSynchronize();\n",
        "  printf(\"Hello from CPU (host) after kernel execution\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P71PB1boHhgz",
        "outputId": "1cbeb6b7-643f-441c-caa3-3615fc8c06ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from CPU (host) before kernel execution\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "\tHello from GPU (device)\n",
            "Hello from CPU (host) after kernel execution\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
